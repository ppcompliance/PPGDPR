[Data]
glove_path = ./emb/glove.6B.100d.txt
bert_path = ./emb/bert-base-uncased/

[Save]
save = True

[Network]
word_dims = 100
dropout_embed = 0.15
dropout_mlp = 0.15
word_num_layers = 2
word_hidden_size = 128
dropout_input = 0.0
dropout_hidden = 0.33

[Optimizer]
learning_rate = 2e-4
bert_lr = 2e-5
decay = .75
decay_steps = 10000
beta_1 = .9
beta_2 = .9
epsilon = 1e-12
clip = 5.0
gamma = 0

[Run]
threads = 2
epochs = 500
train_batch_size = 4
test_batch_size = 4
log_interval = 500
early_stops = 5
save_after = 1
update_every = 2